{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# 3. write a python class representing a discreate random variable with methods to calculate its expected value and variance",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "class DiscreteRandomVariable:  \n    def __init__(self, values, probabilities):  \n       \n        if len(values) != len(probabilities):  \n            raise ValueError(\"Values and probabilities must have the same length.\")  \n        if not (0.999 < sum(probabilities) < 1.001):  # Allow for a small floating-point error  \n            raise ValueError(\"Probabilities must sum to 1.\")  \n          \n        self.values = values  \n        self.probabilities = probabilities  \n  \n    def expected_value(self):  \n        \n        return sum(v * p for v, p in zip(self.values, self.probabilities))  \n  \n    def variance(self):  \n        \n        mean = self.expected_value()  \n        return sum(p * (v - mean) ** 2 for v, p in zip(self.values, self.probabilities))  \n  \n  \n# Example usage  \nvalues = [1, 2, 3, 4, 5]  \nprobabilities = [0.1, 0.2, 0.3, 0.2, 0.2]  \n  \ndrv = DiscreteRandomVariable(values, probabilities)  \nprint(\"Expected Value:\", drv.expected_value())  \nprint(\"Variance:\", drv.variance())  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Expected Value: 3.2\nVariance: 1.56\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": "# 4. Implement a program to simulate the rolling of a six-sided die and calculate the expected value and variance of the outcomes",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import random  \n\nclass DiscreteRandomVariable:  \n    def __init__(self, values, probabilities):  \n       \n        if len(values) != len(probabilities):  \n            raise ValueError(\"Values and probabilities must have the same length.\")  \n        if not (0.999 < sum(probabilities) < 1.001):  # Allow for a small floating-point error  \n            raise ValueError(\"Probabilities must sum to 1.\")  \n          \n        self.values = values  \n        self.probabilities = probabilities  \n  \n    def expected_value(self):  \n       \n        return sum(v * p for v, p in zip(self.values, self.probabilities))  \n  \n    def variance(self):  \n       \n        mean = self.expected_value()  \n        return sum(p * (v - mean) ** 2 for v, p in zip(self.values, self.probabilities))  \n  \n  \ndef simulate_die_rolls(num_rolls):  \n   \n    outcomes = [random.randint(1, 6) for _ in range(num_rolls)]  \n    return outcomes  \n  \ndef calculate_empirical_probabilities(outcomes):  \n   \n    num_rolls = len(outcomes)  \n    probabilities = [outcomes.count(i) / num_rolls for i in range(1, 7)]  \n    return probabilities  \n  \n# Simulate rolling a six-sided die 1000 times  \nnum_rolls = 10 \noutcomes = simulate_die_rolls(num_rolls)\n \n# Calculate empirical probabilities  \nvalues = [1, 2, 3, 4, 5, 6]  \nprobabilities = calculate_empirical_probabilities(outcomes)\n  \n# Create a DiscreteRandomVariable object  \ndrv = DiscreteRandomVariable(values, probabilities)  \n  \n# Calculate and print the expected value and variance  \nprint(\"Expected Value:\", drv.expected_value())  \nprint(\"Variance:\", drv.variance())  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Expected Value: 4.2\nVariance: 3.16\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 17
    },
    {
      "cell_type": "markdown",
      "source": "# 5. Create a Python function to generate random samples 6rom a given probabilities distribution (e.g.,binomial, Poisson) and calculate their mean and variance.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np  \n  \ndef generate_samples_and_calculate_stats(distribution, params, num_samples):  \n    \n    if distribution == 'binomial':  \n        n, p = params  \n        samples = np.random.binomial(n, p, num_samples)  \n    elif distribution == 'poisson':  \n        lambda_ = params[0]  \n        samples = np.random.poisson(lambda_, num_samples)  \n    else:  \n        raise ValueError(\"Unsupported distribution. Use 'binomial' or 'poisson'.\")  \n  \n    mean = np.mean(samples)  \n    variance = np.var(samples)  \n      \n    return samples, mean, variance  \n  \nbinomial_samples, binomial_mean, binomial_variance = generate_samples_and_calculate_stats('binomial', (10, 0.5), 1000)  \nprint(\"Binomial Distribution:\")  \nprint(\"Samples:\", binomial_samples[:10])  # Print first 10 samples for brevity  \nprint(\"Mean:\", binomial_mean)  \nprint(\"Variance:\", binomial_variance)  \n  \n\npoisson_samples, poisson_mean, poisson_variance = generate_samples_and_calculate_stats('poisson', (3,), 1000)  \nprint(\"\\nPoisson Distribution:\")  \nprint(\"Samples:\", poisson_samples[:10])  # Print first 10 samples for brevity  \nprint(\"Mean:\", poisson_mean)  \nprint(\"Variance:\", poisson_variance)  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Binomial Distribution:\nSamples: [4 3 4 8 6 6 6 5 4 6]\nMean: 5.028\nVariance: 2.535216\n\nPoisson Distribution:\nSamples: [1 0 2 4 2 2 1 4 3 3]\nMean: 2.984\nVariance: 3.155744\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": "# 6. Write a Python script to generate random numbers from a Gaussian (normal) distribution and compute the mean, variance, and standard deviation of the samples.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np  \n  \ndef generate_normal_samples(mean, std_dev, num_samples):  \n    \n    # Generate random samples from a normal distribution  \n    samples = np.random.normal(mean, std_dev, num_samples)  \n      \n    # Calculate statistical measures  \n    calculated_mean = np.mean(samples)  \n    calculated_variance = np.var(samples)  \n    calculated_std_dev = np.std(samples)  \n      \n    return samples, calculated_mean, calculated_variance, calculated_std_dev  \n  \n# Example usage:  \n# Generate and analyze 1000 samples from a normal distribution with mean=0 and std_dev=1  \nmean = 0  \nstd_dev = 1  \nnum_samples = 1000  \n  \nsamples, calculated_mean, calculated_variance, calculated_std_dev = generate_normal_samples(mean, std_dev, num_samples)  \n  \nprint(\"Normal Distribution:\")  \nprint(\"Samples:\", samples[:10])  # Print first 10 samples for brevity  \nprint(\"Calculated Mean:\", calculated_mean)  \nprint(\"Calculated Variance:\", calculated_variance)  \nprint(\"Calculated Standard Deviation:\", calculated_std_dev)  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Normal Distribution:\nSamples: [-0.69191998 -0.42690079 -0.82700805  1.59205447  2.16374766 -0.15289059\n  0.7440166  -1.01817353 -0.18605312  0.60167988]\nCalculated Mean: 0.0205451282624916\nCalculated Variance: 1.0698043991992354\nCalculated Standard Deviation: 1.0343134917418584\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "markdown",
      "source": "# 8. Write a Python function to calculate the probability density function (PDF) of a continuous random variable for a given normal distribution.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import math  \n  \ndef normal_pdf(x, mu, sigma):  \n    \n    coefficient = 1 / (sigma * math.sqrt(2 * math.pi))  \n    exponent = -((x - mu) ** 2) / (2 * sigma ** 2)  \n    return coefficient * math.exp(exponent)  \n  \n# Example usage:  \nx = 1.0  \nmu = 0.0  \nsigma = 1.0  \npdf_value = normal_pdf(x, mu, sigma)  \nprint(f\"The PDF of the normal distribution at x={x} is {pdf_value}\")  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "The PDF of the normal distribution at x=1.0 is 0.24197072451914337\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "markdown",
      "source": "# 9. Create a program to calculate the cumulative distribution function (CDF) of exponential distribution.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import math  \n  \ndef exponential_cdf(x, lambd):  \n   \n    if x < 0:  \n        return 0.0  \n    return 1 - math.exp(-lambd * x)  \n  \n# Example usage:  \nx = 2.0  \nlambd = 1.5  \ncdf_value = exponential_cdf(x, lambd)  \nprint(f\"The CDF of the exponential distribution at x={x} with lambda={lambd} is {cdf_value}\")  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "The CDF of the exponential distribution at x=2.0 with lambda=1.5 is 0.950212931632136\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 22
    },
    {
      "cell_type": "markdown",
      "source": "# 10. Write a Python function to calculate the probability mass function (PMF) of Poisson distribution.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import math  \n  \ndef poisson_pmf(k, lambd):    \n    if k < 0:  \n        return 0.0  \n    return (lambd ** k) * math.exp(-lambd) / math.factorial(k)  \n  \n# Example usage:  \nk = 3  \nlambd = 2.5  \npmf_value = poisson_pmf(k, lambd)  \nprint(f\"The PMF of the Poisson distribution at k={k} with lambda={lambd} is {pmf_value}\")  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "The PMF of the Poisson distribution at k=3 with lambda=2.5 is 0.21376301724973645\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 23
    },
    {
      "cell_type": "markdown",
      "source": "# 11. A company wants to test in a new website layout leads to a higher conversion rate (percentage oN visitors who make a purchase). They collect data Nrom the old and new layouts to compare",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np  \nfrom statsmodels.stats.proportion import proportions_ztest  \n  \n# Generate data  \nold_layout = np.array([1] * 50 + [0] * 950)  \nnew_layout = np.array([1] * 70 + [0] * 930)  \n  \n# Calculate the number of successes (purchases) and the number of trials (visitors) for both layouts  \nsuccesses = np.array([old_layout.sum(), new_layout.sum()])  \nnobs = np.array([len(old_layout), len(new_layout)])  \n  \n# Perform the z-test  \nstat, p_value = proportions_ztest(successes, nobs, alternative='larger')  \n  \nprint(f\"Z-statistic: {stat}\")  \nprint(f\"P-value: {p_value}\")  \n  \n# Interpretation  \nalpha = 0.05  # significance level  \nif p_value < alpha:  \n    print(\"Reject the null hypothesis: The new layout leads to a higher conversion rate.\")  \nelse:  \n    print(\"Fail to reject the null hypothesis: There is no significant difference in conversion rates.\")  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Z-statistic: -1.883108942886774\nP-value: 0.9701571972337869\nFail to reject the null hypothesis: There is no significant difference in conversion rates.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": "# 12. A tutoring service claims that its program improves students' exam scores. A sample of students who participated in the program was taken, and their scores before and after the program were recorded",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np  \nfrom scipy.stats import norm  \n  \n# Given data  \nbefore_program = np.array([75, 80, 85, 70, 90, 78, 92, 88, 82, 87])  \nafter_program = np.array([80, 85, 90, 80, 92, 80, 95, 90, 85, 88])  \n  \n# Calculate the differences  \ndifferences = after_program - before_program  \n  \n# Calculate mean and standard deviation of the differences  \nmean_diff = np.mean(differences)  \nstd_diff = np.std(differences, ddof=1)  # Use ddof=1 for sample standard deviation  \nn = len(differences)  \n  \n# Calculate the z-score  \nz_score = mean_diff / (std_diff / np.sqrt(n))  \n  \n# Calculate the p-value  \np_value = 2 * (1 - norm.cdf(abs(z_score)))  # Two-tailed test  \n  \n# Output the results  \nprint(\"Mean of differences:\", mean_diff)  \nprint(\"Standard deviation of differences:\", std_diff)  \nprint(\"Z-score:\", z_score)  \nprint(\"P-value:\", p_value)  \n  \n# Decision based on p-value  \nalpha = 0.05  \nif p_value < alpha:  \n    print(\"Reject the null hypothesis: The tutoring program has a significant effect on exam scores.\")  \nelse:  \n    print(\"Fail to reject the null hypothesis: There is no significant effect of the tutoring program on exam scores.\")  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean of differences: 3.8\nStandard deviation of differences: 2.616188916046478\nZ-score: 4.593190894944668\nP-value: 4.365194105293568e-06\nReject the null hypothesis: The tutoring program has a significant effect on exam scores.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "markdown",
      "source": "# 13. A pharmaceutical company wants to determine if a new drug is effective in reducing blood pressure. They conduct a study and record blood pressure measurements before and after administering the drug.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np  \nfrom scipy.stats import norm  \n  \n# Given data  \nbefore_drug = np.array([145, 150, 140, 135, 155, 160, 152, 148, 130, 138])  \nafter_drug = np.array([130, 140, 132, 128, 145, 148, 138, 136, 125, 130])  \n  \n# Calculate the differences  \ndifferences = after_drug - before_drug  \n  \n# Calculate mean and standard deviation of the differences  \nmean_diff = np.mean(differences)  \nstd_diff = np.std(differences, ddof=1)  # Use ddof=1 for sample standard deviation  \nn = len(differences)  \n  \n# Calculate the z-score  \nz_score = mean_diff / (std_diff / np.sqrt(n))  \n  \n# Calculate the p-value  \np_value = 2 * (1 - norm.cdf(abs(z_score)))  # Two-tailed test  \n  \n# Output the results  \nprint(\"Mean of differences:\", mean_diff)  \nprint(\"Standard deviation of differences:\", std_diff)  \nprint(\"Z-score:\", z_score)  \nprint(\"P-value:\", p_value)  \n  \n# Decision based on p-value  \nalpha = 0.05  \nif p_value < alpha:  \n    print(\"Reject the null hypothesis: The drug has a significant effect on reducing blood pressure.\")  \nelse:  \n    print(\"Fail to reject the null hypothesis: There is no significant effect of the drug on blood pressure.\")  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean of differences: -10.1\nStandard deviation of differences: 3.178049716414141\nZ-score: -10.049875621120888\nP-value: 0.0\nReject the null hypothesis: The drug has a significant effect on reducing blood pressure.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": "# 14. A customer service department claims that their average response time is less than 5 minutes. A sample of recent customer interactions was taken, and the response times were recorded.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np  \nfrom scipy.stats import norm  \n  \n# Given data  \nresponse_times = np.array([4.3, 3.8, 5.1, 4.9, 4.7, 4.2, 5.2, 4.5, 4.6, 4.4])  \n  \n# Population mean  \nmu = 5  \n  \n# Calculate sample mean and standard deviation  \nsample_mean = np.mean(response_times)  \nsample_std = np.std(response_times, ddof=1)  # Use ddof=1 for sample standard deviation  \nn = len(response_times)  \n  \n# Calculate the z-score  \nz_score = (sample_mean - mu) / (sample_std / np.sqrt(n))  \n  \n# Calculate the p-value  \np_value = norm.cdf(z_score)  # One-tailed test  \n  \n# Output the results  \nprint(\"Sample mean:\", sample_mean)  \nprint(\"Sample standard deviation:\", sample_std)  \nprint(\"Z-score:\", z_score)  \nprint(\"P-value:\", p_value)  \n  \n# Decision based on p-value  \nalpha = 0.05  \nif p_value < alpha:  \n    print(\"Reject the null hypothesis: The customer service department's average response time is less than 5 minutes.\")  \nelse:  \n    print(\"Fail to reject the null hypothesis: There is no significant evidence that the average response time is less than 5 minutes.\")  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Sample mean: 4.57\nSample standard deviation: 0.4270050741306634\nZ-score: -3.184457226042963\nP-value: 0.0007251287113068958\nReject the null hypothesis: The customer service department's average response time is less than 5 minutes.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "markdown",
      "source": "# 15. A company is testing two different website layouts to see which one leads to higher click-through rates. Write a Python function to perform an A/B test analysis, including calculating the t-statistic, degrees of freedom, and p-value.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np  \nfrom scipy.stats import t  \n  \n# Given data  \nlayout_a_clicks = [28, 32, 33, 29, 31, 34, 30, 35, 36, 37]  \nlayout_b_clicks = [40, 41, 38, 42, 39, 44, 43, 41, 45, 47]  \n  \ndef ab_test_analysis(layout_a, layout_b):  \n    # Convert lists to numpy arrays for easier calculations  \n    layout_a = np.array(layout_a)  \n    layout_b = np.array(layout_b)  \n      \n    # Calculate means  \n    mean_a = np.mean(layout_a)  \n    mean_b = np.mean(layout_b)  \n      \n    # Calculate standard deviations  \n    std_a = np.std(layout_a, ddof=1)  # Use ddof=1 for sample standard deviation  \n    std_b = np.std(layout_b, ddof=1)  \n      \n    # Calculate sample sizes  \n    n_a = len(layout_a)  \n    n_b = len(layout_b)  \n      \n    # Calculate the t-statistic  \n    t_stat = (mean_a - mean_b) / np.sqrt((std_a**2 / n_a) + (std_b**2 / n_b))  \n      \n    # Calculate degrees of freedom  \n    df = ((std_a**2 / n_a) + (std_b**2 / n_b))**2 / (((std_a**2 / n_a)**2 / (n_a - 1)) + ((std_b**2 / n_b)**2 / (n_b - 1)))  \n      \n    # Calculate the p-value (two-tailed test)  \n    p_value = 2 * (1 - t.cdf(abs(t_stat), df))  \n      \n    return t_stat, df, p_value  \n  \n# Perform the A/B test analysis  \nt_stat, df, p_value = ab_test_analysis(layout_a_clicks, layout_b_clicks)  \n  \n# Output the results  \nprint(\"T-statistic:\", t_stat)  \nprint(\"Degrees of freedom:\", df)  \nprint(\"P-value:\", p_value)  \n  \n# Decision based on p-value  \nalpha = 0.05  \nif p_value < alpha:  \n    print(\"Reject the null hypothesis: There is a significant difference in click-through rates between the two layouts.\")  \nelse:  \n    print(\"Fail to reject the null hypothesis: There is no significant difference in click-through rates between the two layouts.\")  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "T-statistic: -7.298102156175071\nDegrees of freedom: 17.879871863320876\nP-value: 9.19659607134804e-07\nReject the null hypothesis: There is a significant difference in click-through rates between the two layouts.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "markdown",
      "source": "# 16. A pharmaceutical company wants to determine if a new drug is more effective than an existing drug in reducing cholesterol levels. Create a program to analyze the clinical trial data and calculate the t-statistic and p-value for the treatment effect.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np  \nfrom scipy.stats import t  \n  \n# Given data  \nexisting_drug_levels = [180, 182, 175, 185, 178, 176, 172, 184, 179, 183]  \nnew_drug_levels = [170, 172, 165, 168, 175, 173, 170, 178, 172, 176]  \n  \ndef analyze_clinical_trial(existing_levels, new_levels):  \n    # Convert lists to numpy arrays for easier calculations  \n    existing_levels = np.array(existing_levels)  \n    new_levels = np.array(new_levels)  \n      \n    # Calculate means  \n    mean_existing = np.mean(existing_levels)  \n    mean_new = np.mean(new_levels)  \n      \n    # Calculate standard deviations  \n    std_existing = np.std(existing_levels, ddof=1)  # Use ddof=1 for sample standard deviation  \n    std_new = np.std(new_levels, ddof=1)  \n      \n    # Calculate sample sizes  \n    n_existing = len(existing_levels)  \n    n_new = len(new_levels)  \n      \n    # Calculate the t-statistic  \n    t_stat = (mean_existing - mean_new) / np.sqrt((std_existing**2 / n_existing) + (std_new**2 / n_new))  \n      \n    # Calculate degrees of freedom  \n    df = ((std_existing**2 / n_existing) + (std_new**2 / n_new))**2 / (((std_existing**2 / n_existing)**2 / (n_existing - 1)) + ((std_new**2 / n_new)**2 / (n_new - 1)))  \n      \n    # Calculate the p-value (one-tailed test)  \n    p_value = 1 - t.cdf(t_stat, df)  \n      \n    return t_stat, df, p_value  \n  \n# Perform the clinical trial analysis  \nt_stat, df, p_value = analyze_clinical_trial(existing_drug_levels, new_drug_levels)  \n  \n# Output the results  \nprint(\"T-statistic:\", t_stat)  \nprint(\"Degrees of freedom:\", df)  \nprint(\"P-value:\", p_value)  \n  \n# Decision based on p-value  \nalpha = 0.05  \nif p_value < alpha:  \n    print(\"Reject the null hypothesis: The new drug is more effective in reducing cholesterol levels than the existing drug.\")  \nelse:  \n    print(\"Fail to reject the null hypothesis: There is no significant evidence that the new drug is more effective in reducing cholesterol levels than the existing drug.\")  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "T-statistic: 4.140480986208661\nDegrees of freedom: 17.866770765582338\nP-value: 0.0003114614472734534\nReject the null hypothesis: The new drug is more effective in reducing cholesterol levels than the existing drug.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 29
    },
    {
      "cell_type": "markdown",
      "source": "# 17. A school district introduces an educational intervention program to improve math scores. Write a Python function to analyze pre- and post-intervention test scores, calculating the t-statistic and p-value to determine if the intervention had a significant impact.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from scipy import stats  \n  \ndef analyze_intervention(pre_scores, post_scores):  \n    # Check if the lengths of the score lists are equal  \n    if len(pre_scores) != len(post_scores):  \n        raise ValueError(\"The lengths of pre-intervention and post-intervention scores must be the same.\")  \n      \n    # Perform paired t-test  \n    t_statistic, p_value = stats.ttest_rel(pre_scores, post_scores)  \n      \n    return t_statistic, p_value  \n  \n# Data  \npre_intervention_scores = [80, 85, 90, 75, 88, 82, 92, 78, 85, 87]  \npost_intervention_scores = [90, 92, 88, 92, 95, 91, 96, 93, 89, 93]  \n  \n# Analyze the intervention  \nt_stat, p_val = analyze_intervention(pre_intervention_scores, post_intervention_scores)  \n  \nprint(f\"T-statistic: {t_stat}\")  \nprint(f\"P-value: {p_val}\")  \n  \n# Determine significance  \nalpha = 0.05  \nif p_val < alpha:  \n    print(\"The intervention had a significant impact on the test scores.\")  \nelse:  \n    print(\"The intervention did not have a significant impact on the test scores.\")  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "T-statistic: -4.42840883965761\nP-value: 0.0016509548165795493\nThe intervention had a significant impact on the test scores.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 32
    },
    {
      "cell_type": "markdown",
      "source": "# 18. An HR department wants to investigate if there's a gender-based salary gap within the company. Develop a program to analyze salary data, calculate the t-statistic, and determine if there's a statistically significant difference between the average salaries of male and female employees.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np  \nfrom scipy import stats  \n  \n# Generate synthetic salary data for male and female employees  \nnp.random.seed(0)  # For reproducibility  \nmale_salaries = np.random.normal(loc=50000, scale=10000, size=20)  \nfemale_salaries = np.random.normal(loc=55000, scale=9000, size=20)  \n  \n# Calculate the means and standard deviations  \nmean_male = np.mean(male_salaries)  \nmean_female = np.mean(female_salaries)  \nstd_male = np.std(male_salaries, ddof=1)  \nstd_female = np.std(female_salaries, ddof=1)  \n  \nprint(f\"Mean salary for males: ${mean_male:.2f}\")  \nprint(f\"Mean salary for females: ${mean_female:.2f}\")  \nprint(f\"Standard deviation for male salaries: ${std_male:.2f}\")  \nprint(f\"Standard deviation for female salaries: ${std_female:.2f}\")  \n  \n# Perform a two-sample t-test  \nt_statistic, p_value = stats.ttest_ind(male_salaries, female_salaries)  \n  \nprint(f\"T-statistic: {t_statistic:.2f}\")  \nprint(f\"P-value: {p_value:.4f}\")  \n  \n# Determine if there is a statistically significant difference  \nalpha = 0.05  \nif p_value < alpha:  \n    print(\"There is a statistically significant difference between male and female salaries.\")  \nelse:  \n    print(\"There is no statistically significant difference between male and female salaries.\")  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean salary for males: $55693.35\nMean salary for females: $55501.75\nStandard deviation for male salaries: $8722.69\nStandard deviation for female salaries: $10968.10\nT-statistic: 0.06\nP-value: 0.9516\nThere is no statistically significant difference between male and female salaries.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 33
    },
    {
      "cell_type": "markdown",
      "source": "# 19. A manufacturer produces two different versions o a product and wants to compare their quality scores. Create a Python function to analyze quality assessment data, calculate the t-statistic, and decide whether there's a significant difference in quality between the two versions.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "from scipy import stats  \n  \ndef analyze_quality(version1_scores, version2_scores):  \n    # Perform independent two-sample t-test  \n    t_statistic, p_value = stats.ttest_ind(version1_scores, version2_scores)  \n      \n    return t_statistic, p_value  \n  \n# Data  \nversion1_scores = [85, 88, 82, 89, 87, 84, 90, 88, 85, 86, 91, 83, 87, 84, 89, 86, 84, 88, 85, 86, 89, 90, 87, 88, 85]  \nversion2_scores = [80, 78, 83, 81, 79, 82, 76, 80, 78, 81, 77, 82, 80, 79, 82, 79, 80, 81, 79, 82, 79, 78, 80, 81, 82]  \n  \n# Analyze the quality scores  \nt_stat, p_val = analyze_quality(version1_scores, version2_scores)  \n  \nprint(f\"T-statistic: {t_stat}\")  \nprint(f\"P-value: {p_val}\")  \n  \n# Determine significance  \nalpha = 0.05  \nif p_val < alpha:  \n    print(\"There is a significant difference in quality between the two versions.\")  \nelse:  \n    print(\"There is no significant difference in quality between the two versions.\")  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "T-statistic: 11.325830417646698\nP-value: 3.6824250702873965e-15\nThere is a significant difference in quality between the two versions.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 31
    },
    {
      "cell_type": "markdown",
      "source": "# 20. A restaurant chain collects customer satisfaction scores for two different branches. Write a program to analyze the scores, calculate the t-statistic, and determine if there's a statistically significant difference in customer satisfaction between the branches",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np  \nfrom scipy import stats  \n  \n# Customer satisfaction scores  \nbranch_a_scores = [4, 5, 3, 4, 5, 4, 5, 3, 4, 4, 5, 4, 4, 3, 4, 5, 5, 4, 3, 4, 5, 4, 3, 5, 4, 4, 5, 3, 4, 5, 4]  \nbranch_b_scores = [3, 4, 2, 3, 4, 3, 4, 2, 3, 3, 4, 3, 3, 2, 3, 4, 4, 3, 2, 3, 4, 3, 2, 4, 3, 3, 4, 2, 3, 4, 3]  \n  \n# Convert lists to numpy arrays for easier calculations  \nbranch_a_scores = np.array(branch_a_scores)  \nbranch_b_scores = np.array(branch_b_scores)  \n  \n# Calculate the means and standard deviations  \nmean_a = np.mean(branch_a_scores)  \nmean_b = np.mean(branch_b_scores)  \nstd_a = np.std(branch_a_scores, ddof=1)  \nstd_b = np.std(branch_b_scores, ddof=1)  \n  \nprint(f\"Mean satisfaction score for Branch A: {mean_a:.2f}\")  \nprint(f\"Mean satisfaction score for Branch B: {mean_b:.2f}\")  \nprint(f\"Standard deviation for Branch A scores: {std_a:.2f}\")  \nprint(f\"Standard deviation for Branch B scores: {std_b:.2f}\")  \n  \n# Perform a two-sample t-test  \nt_statistic, p_value = stats.ttest_ind(branch_a_scores, branch_b_scores)  \n  \nprint(f\"T-statistic: {t_statistic:.2f}\")  \nprint(f\"P-value: {p_value:.4f}\")  \n  \n# Determine if there is a statistically significant difference  \nalpha = 0.05  \nif p_value < alpha:  \n    print(\"There is a statistically significant difference in customer satisfaction between the branches.\")  \nelse:  \n    print(\"There is no statistically significant difference in customer satisfaction between the branches.\")  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Mean satisfaction score for Branch A: 4.13\nMean satisfaction score for Branch B: 3.13\nStandard deviation for Branch A scores: 0.72\nStandard deviation for Branch B scores: 0.72\nT-statistic: 5.48\nP-value: 0.0000\nThere is a statistically significant difference in customer satisfaction between the branches.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 34
    },
    {
      "cell_type": "markdown",
      "source": "# 21. A political analyst wants to determine if there is a significant association between age groups and voter preferences. (Candidate A or Candidate B). They collect data from a sample of 500 voters and classify them into different age groups and candidate preferences. Perform a Chi-Square test to determine if there is a significant association between age groups and voter preferences.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np  \nimport pandas as pd  \nfrom scipy.stats import chi2_contingency  \n  \n# Generate data  \nnp.random.seed(0)  \nage_groups = np.random.choice(['18-30', '31-50', '51+'], size=500)  \nvoter_preferences = np.random.choice(['Candidate A', 'Candidate B'], size=500)  \n  \n# Create a contingency table  \ndata = pd.DataFrame({'Age Group': age_groups, 'Voter Preference': voter_preferences})  \ncontingency_table = pd.crosstab(data['Age Group'], data['Voter Preference'])  \n  \nprint(\"Contingency Table:\")  \nprint(contingency_table)  \n  \n# Perform the Chi-Square test  \nchi2, p, dof, expected = chi2_contingency(contingency_table)  \n  \nprint(f\"\\nChi-Square Statistic: {chi2:.2f}\")  \nprint(f\"P-value: {p:.4f}\")  \nprint(f\"Degrees of Freedom: {dof}\")  \n  \n# Determine if there is a statistically significant association  \nalpha = 0.05  \nif p < alpha:  \n    print(\"There is a statistically significant association between age groups and voter preferences.\")  \nelse:  \n    print(\"There is no statistically significant association between age groups and voter preferences.\")  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Contingency Table:\nVoter Preference  Candidate A  Candidate B\nAge Group                                 \n18-30                      95           87\n31-50                      87           82\n51+                        84           65\n\nChi-Square Statistic: 0.88\nP-value: 0.6447\nDegrees of Freedom: 2\nThere is no statistically significant association between age groups and voter preferences.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 35
    },
    {
      "cell_type": "markdown",
      "source": "# 22. A company conducted a customer satisfaction survey to determine if there is a significant relationship between product satisfaction levels (Satisfied, Neutral, Dissatisfied) and the region where customers are located (East, West, North, South). The survey data is summarized in a contingency table. Conduct a ChiSquare test to determine if there is a significant relationship between product satisfaction levels and customer regions.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np  \nfrom scipy.stats import chi2_contingency  \n  \n# Sample data: Product satisfaction levels (rows) vs. Customer regions (columns)  \ndata = np.array([[50, 30, 40, 20], [30, 40, 30, 50], [20, 30, 40, 30]])  \n  \n# Display the contingency table  \nprint(\"Contingency Table:\")  \nprint(data)  \n  \n# Perform the Chi-Square test  \nchi2, p, dof, expected = chi2_contingency(data)  \n  \nprint(f\"\\nChi-Square Statistic: {chi2:.2f}\")  \nprint(f\"P-value: {p:.4f}\")  \nprint(f\"Degrees of Freedom: {dof}\")  \nprint(\"\\nExpected Frequencies:\")  \nprint(expected)  \n  \n# Determine if there is a statistically significant relationship  \nalpha = 0.05  \nif p < alpha:  \n    print(\"There is a statistically significant relationship between product satisfaction levels and customer regions.\")  \nelse:  \n    print(\"There is no statistically significant relationship between product satisfaction levels and customer regions.\")  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Contingency Table:\n[[50 30 40 20]\n [30 40 30 50]\n [20 30 40 30]]\n\nChi-Square Statistic: 27.78\nP-value: 0.0001\nDegrees of Freedom: 6\n\nExpected Frequencies:\n[[34.14634146 34.14634146 37.56097561 34.14634146]\n [36.58536585 36.58536585 40.24390244 36.58536585]\n [29.26829268 29.26829268 32.19512195 29.26829268]]\nThere is a statistically significant relationship between product satisfaction levels and customer regions.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 36
    },
    {
      "cell_type": "markdown",
      "source": "# 23. A company implemented an employee training program to improve job performance (Effective, Neutral, Ineffective). After the training, they collected data from a sample of employees and classified them based on their job performance before and after the training. Perform a Chi-Square test to determine if there is a significant difference between job performance levels before and after the training.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np  \nfrom scipy.stats import chi2_contingency  \n  \n# Sample data: Job performance levels before (rows) and after (columns) training  \ndata = np.array([[50, 30, 20], [30, 40, 30], [20, 30, 40]])  \n  \n# Display the contingency table  \nprint(\"Contingency Table:\")  \nprint(data)  \n  \n# Perform the Chi-Square test  \nchi2, p, dof, expected = chi2_contingency(data)  \n  \nprint(f\"\\nChi-Square Statistic: {chi2:.2f}\")  \nprint(f\"P-value: {p:.4f}\")  \nprint(f\"Degrees of Freedom: {dof}\")  \nprint(\"\\nExpected Frequencies:\")  \nprint(expected)  \n  \n# Determine if there is a statistically significant difference  \nalpha = 0.05  \nif p < alpha:  \n    print(\"There is a statistically significant difference between job performance levels before and after the training.\")  \nelse:  \n    print(\"There is no statistically significant difference between job performance levels before and after the training.\")  \n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Contingency Table:\n[[50 30 20]\n [30 40 30]\n [20 30 40]]\n\nChi-Square Statistic: 22.16\nP-value: 0.0002\nDegrees of Freedom: 4\n\nExpected Frequencies:\n[[34.48275862 34.48275862 31.03448276]\n [34.48275862 34.48275862 31.03448276]\n [31.03448276 31.03448276 27.93103448]]\nThere is a statistically significant difference between job performance levels before and after the training.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 37
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}